{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.001\n",
    "\n",
    "log_interval = 10\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('./files/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('./files/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "print(example_data.shape)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "  plt.subplot(2,3,i+1)\n",
    "  plt.tight_layout()\n",
    "  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "  plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, size=10):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, size)\n",
    "        self.fc2 = nn.Linear(size, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        assert x.shape[1:] == torch.Size((1, 28, 28))\n",
    "        b = x.shape[0]\n",
    "        x = x.view(b, 28 * 28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(size=10, epochs=20, step=5, weight_decay=0.0001):\n",
    "    network = Net(size=size)\n",
    "    network_loss = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        network.parameters(), \n",
    "        lr=learning_rate,\n",
    "        weight_decay=weight_decay)\n",
    "    \n",
    "    def train():\n",
    "      network.train()\n",
    "      train_loss = 0\n",
    "      correct = 0\n",
    "      for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        loss = network_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "\n",
    "      train_loss /= len(train_loader.dataset)\n",
    "      print('\\nTrain set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        train_loss, correct, len(train_loader.dataset),\n",
    "        100. * correct / len(train_loader.dataset)))       \n",
    "\n",
    "    def test():\n",
    "      network.eval()\n",
    "      test_loss = 0\n",
    "      correct = 0\n",
    "      with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "          output = network(data)\n",
    "          test_loss += network_loss(output, target).item()\n",
    "          pred = output.data.max(1, keepdim=True)[1]\n",
    "          correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "      test_loss /= len(test_loader.dataset)\n",
    "      print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))\n",
    "          \n",
    "    test()\n",
    "    for epoch in range(1, epochs + 1):\n",
    "      train()\n",
    "      test()       \n",
    "      if epoch % step == 0:\n",
    "        weights = {x: y.cpu().numpy() for x,y in network.state_dict().items()} \n",
    "        with open(f\"weights/{size}_{epoch}_{weight_decay}.pkl\", \"wb\") as file:\n",
    "            pkl.dump(weights, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 5\n",
      "\n",
      "Test set: Avg. loss: 0.0023, Accuracy: 1449/10000 (14%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0127, Accuracy: 44708/60000 (75%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005, Accuracy: 8477/10000 (85%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0082, Accuracy: 50947/60000 (85%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005, Accuracy: 8606/10000 (86%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0077, Accuracy: 51582/60000 (86%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005, Accuracy: 8678/10000 (87%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0072, Accuracy: 52041/60000 (87%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004, Accuracy: 8724/10000 (87%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0068, Accuracy: 52412/60000 (87%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004, Accuracy: 8753/10000 (88%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0066, Accuracy: 52666/60000 (88%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004, Accuracy: 8790/10000 (88%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0064, Accuracy: 52916/60000 (88%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004, Accuracy: 8823/10000 (88%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0063, Accuracy: 53058/60000 (88%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004, Accuracy: 8854/10000 (89%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0062, Accuracy: 53130/60000 (89%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004, Accuracy: 8812/10000 (88%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0061, Accuracy: 53204/60000 (89%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004, Accuracy: 8867/10000 (89%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0060, Accuracy: 53265/60000 (89%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004, Accuracy: 8849/10000 (88%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0060, Accuracy: 53359/60000 (89%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004, Accuracy: 8842/10000 (88%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0059, Accuracy: 53337/60000 (89%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004, Accuracy: 8840/10000 (88%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0059, Accuracy: 53326/60000 (89%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004, Accuracy: 8902/10000 (89%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0058, Accuracy: 53478/60000 (89%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004, Accuracy: 8905/10000 (89%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0058, Accuracy: 53505/60000 (89%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004, Accuracy: 8883/10000 (89%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0058, Accuracy: 53542/60000 (89%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004, Accuracy: 8846/10000 (88%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0057, Accuracy: 53545/60000 (89%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004, Accuracy: 8892/10000 (89%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0057, Accuracy: 53576/60000 (89%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004, Accuracy: 8891/10000 (89%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0057, Accuracy: 53612/60000 (89%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004, Accuracy: 8878/10000 (89%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0057, Accuracy: 53628/60000 (89%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004, Accuracy: 8897/10000 (89%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0057, Accuracy: 53642/60000 (89%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004, Accuracy: 8875/10000 (89%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0057, Accuracy: 53658/60000 (89%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004, Accuracy: 8877/10000 (89%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0056, Accuracy: 53702/60000 (90%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004, Accuracy: 8870/10000 (89%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0056, Accuracy: 53717/60000 (90%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004, Accuracy: 8856/10000 (89%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0056, Accuracy: 53741/60000 (90%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004, Accuracy: 8880/10000 (89%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0056, Accuracy: 53728/60000 (90%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004, Accuracy: 8898/10000 (89%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0056, Accuracy: 53733/60000 (90%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004, Accuracy: 8880/10000 (89%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0056, Accuracy: 53776/60000 (90%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004, Accuracy: 8883/10000 (89%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0055, Accuracy: 53761/60000 (90%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004, Accuracy: 8871/10000 (89%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0055, Accuracy: 53747/60000 (90%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004, Accuracy: 8917/10000 (89%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0055, Accuracy: 53705/60000 (90%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004, Accuracy: 8915/10000 (89%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0055, Accuracy: 53787/60000 (90%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004, Accuracy: 8908/10000 (89%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0055, Accuracy: 53813/60000 (90%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004, Accuracy: 8899/10000 (89%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0055, Accuracy: 53772/60000 (90%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004, Accuracy: 8902/10000 (89%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0055, Accuracy: 53834/60000 (90%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004, Accuracy: 8885/10000 (89%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0055, Accuracy: 53815/60000 (90%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004, Accuracy: 8872/10000 (89%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0055, Accuracy: 53831/60000 (90%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004, Accuracy: 8904/10000 (89%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0054, Accuracy: 53819/60000 (90%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004, Accuracy: 8896/10000 (89%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0054, Accuracy: 53857/60000 (90%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004, Accuracy: 8918/10000 (89%)\n",
      "\n",
      "Size: 10\n",
      "\n",
      "Test set: Avg. loss: 0.0023, Accuracy: 795/10000 (8%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0084, Accuracy: 50398/60000 (84%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9054/10000 (91%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0048, Accuracy: 54641/60000 (91%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9168/10000 (92%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0044, Accuracy: 55125/60000 (92%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9201/10000 (92%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0042, Accuracy: 55356/60000 (92%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9264/10000 (93%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0039, Accuracy: 55716/60000 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9251/10000 (93%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0038, Accuracy: 55791/60000 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9283/10000 (93%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0037, Accuracy: 55936/60000 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9308/10000 (93%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0036, Accuracy: 56040/60000 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9295/10000 (93%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0035, Accuracy: 56102/60000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9295/10000 (93%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0034, Accuracy: 56222/60000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9308/10000 (93%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0034, Accuracy: 56203/60000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9283/10000 (93%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0034, Accuracy: 56229/60000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9312/10000 (93%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0033, Accuracy: 56316/60000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9340/10000 (93%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0033, Accuracy: 56391/60000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9340/10000 (93%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0032, Accuracy: 56411/60000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9329/10000 (93%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0032, Accuracy: 56452/60000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9347/10000 (93%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0032, Accuracy: 56442/60000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9379/10000 (94%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0031, Accuracy: 56499/60000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9385/10000 (94%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0031, Accuracy: 56495/60000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9356/10000 (94%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0031, Accuracy: 56522/60000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9371/10000 (94%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0031, Accuracy: 56537/60000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9373/10000 (94%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0030, Accuracy: 56580/60000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9327/10000 (93%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0030, Accuracy: 56571/60000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9380/10000 (94%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0030, Accuracy: 56565/60000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9368/10000 (94%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0030, Accuracy: 56678/60000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9361/10000 (94%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0030, Accuracy: 56635/60000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9334/10000 (93%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0030, Accuracy: 56701/60000 (95%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9381/10000 (94%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0030, Accuracy: 56624/60000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9338/10000 (93%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0030, Accuracy: 56623/60000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9364/10000 (94%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0029, Accuracy: 56729/60000 (95%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9385/10000 (94%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0029, Accuracy: 56670/60000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9368/10000 (94%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0029, Accuracy: 56711/60000 (95%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9378/10000 (94%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0029, Accuracy: 56728/60000 (95%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9373/10000 (94%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0029, Accuracy: 56710/60000 (95%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9369/10000 (94%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0029, Accuracy: 56750/60000 (95%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9354/10000 (94%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0028, Accuracy: 56751/60000 (95%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9351/10000 (94%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0028, Accuracy: 56770/60000 (95%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9362/10000 (94%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0028, Accuracy: 56784/60000 (95%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9323/10000 (93%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0028, Accuracy: 56814/60000 (95%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9379/10000 (94%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0028, Accuracy: 56792/60000 (95%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9370/10000 (94%)\n",
      "\n",
      "Size: 15\n",
      "\n",
      "Test set: Avg. loss: 0.0023, Accuracy: 1706/10000 (17%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0067, Accuracy: 52538/60000 (88%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0003, Accuracy: 9207/10000 (92%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0040, Accuracy: 55466/60000 (92%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9323/10000 (93%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0036, Accuracy: 56029/60000 (93%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9379/10000 (94%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0033, Accuracy: 56327/60000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9391/10000 (94%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0031, Accuracy: 56486/60000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9403/10000 (94%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0030, Accuracy: 56669/60000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9405/10000 (94%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0029, Accuracy: 56732/60000 (95%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9430/10000 (94%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0028, Accuracy: 56873/60000 (95%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9434/10000 (94%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0027, Accuracy: 57004/60000 (95%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9422/10000 (94%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0026, Accuracy: 57045/60000 (95%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9448/10000 (94%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0026, Accuracy: 57054/60000 (95%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9431/10000 (94%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0025, Accuracy: 57093/60000 (95%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9435/10000 (94%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0025, Accuracy: 57177/60000 (95%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9434/10000 (94%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0024, Accuracy: 57230/60000 (95%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9462/10000 (95%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0024, Accuracy: 57275/60000 (95%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9451/10000 (95%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0023, Accuracy: 57323/60000 (96%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9474/10000 (95%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0023, Accuracy: 57338/60000 (96%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9481/10000 (95%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0023, Accuracy: 57394/60000 (96%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9498/10000 (95%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0022, Accuracy: 57417/60000 (96%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9461/10000 (95%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0022, Accuracy: 57408/60000 (96%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9485/10000 (95%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0022, Accuracy: 57472/60000 (96%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9504/10000 (95%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0022, Accuracy: 57445/60000 (96%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9484/10000 (95%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0021, Accuracy: 57528/60000 (96%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9453/10000 (95%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0021, Accuracy: 57532/60000 (96%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9485/10000 (95%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0021, Accuracy: 57555/60000 (96%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9482/10000 (95%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0021, Accuracy: 57552/60000 (96%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9491/10000 (95%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0021, Accuracy: 57605/60000 (96%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9463/10000 (95%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0020, Accuracy: 57551/60000 (96%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9455/10000 (95%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0020, Accuracy: 57620/60000 (96%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9472/10000 (95%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0020, Accuracy: 57651/60000 (96%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9489/10000 (95%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0020, Accuracy: 57653/60000 (96%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9482/10000 (95%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0020, Accuracy: 57690/60000 (96%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9457/10000 (95%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0020, Accuracy: 57655/60000 (96%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9496/10000 (95%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0020, Accuracy: 57712/60000 (96%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9475/10000 (95%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0019, Accuracy: 57704/60000 (96%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9490/10000 (95%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0019, Accuracy: 57733/60000 (96%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9498/10000 (95%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0019, Accuracy: 57751/60000 (96%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9484/10000 (95%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0019, Accuracy: 57767/60000 (96%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9446/10000 (94%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0019, Accuracy: 57729/60000 (96%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9498/10000 (95%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0019, Accuracy: 57708/60000 (96%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9475/10000 (95%)\n",
      "\n",
      "Size: 20\n",
      "\n",
      "Test set: Avg. loss: 0.0023, Accuracy: 978/10000 (10%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0060, Accuracy: 53492/60000 (89%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9342/10000 (93%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0032, Accuracy: 56406/60000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9474/10000 (95%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0027, Accuracy: 56992/60000 (95%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9490/10000 (95%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0024, Accuracy: 57274/60000 (95%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9511/10000 (95%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0022, Accuracy: 57509/60000 (96%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9539/10000 (95%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0021, Accuracy: 57638/60000 (96%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0001, Accuracy: 9591/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0019, Accuracy: 57738/60000 (96%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0001, Accuracy: 9562/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0019, Accuracy: 57875/60000 (96%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0001, Accuracy: 9596/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0018, Accuracy: 57971/60000 (97%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0001, Accuracy: 9570/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0017, Accuracy: 58022/60000 (97%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0001, Accuracy: 9608/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0016, Accuracy: 58130/60000 (97%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0001, Accuracy: 9570/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0016, Accuracy: 58170/60000 (97%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0001, Accuracy: 9589/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0015, Accuracy: 58189/60000 (97%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0001, Accuracy: 9588/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0015, Accuracy: 58210/60000 (97%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9590/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0015, Accuracy: 58277/60000 (97%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0001, Accuracy: 9581/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0014, Accuracy: 58332/60000 (97%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0001, Accuracy: 9594/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0014, Accuracy: 58376/60000 (97%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0001, Accuracy: 9603/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0014, Accuracy: 58434/60000 (97%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9585/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0013, Accuracy: 58422/60000 (97%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9571/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0013, Accuracy: 58459/60000 (97%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9587/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0013, Accuracy: 58456/60000 (97%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9581/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0013, Accuracy: 58548/60000 (98%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9594/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0012, Accuracy: 58561/60000 (98%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9569/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0012, Accuracy: 58562/60000 (98%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9574/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0012, Accuracy: 58594/60000 (98%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9601/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0012, Accuracy: 58603/60000 (98%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9568/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0011, Accuracy: 58647/60000 (98%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9569/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0011, Accuracy: 58637/60000 (98%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9590/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0011, Accuracy: 58699/60000 (98%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9561/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0011, Accuracy: 58698/60000 (98%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9590/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0011, Accuracy: 58709/60000 (98%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9558/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0011, Accuracy: 58727/60000 (98%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9576/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0011, Accuracy: 58726/60000 (98%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9574/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0010, Accuracy: 58752/60000 (98%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9568/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0010, Accuracy: 58754/60000 (98%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9583/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0010, Accuracy: 58809/60000 (98%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9565/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0010, Accuracy: 58785/60000 (98%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9563/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0010, Accuracy: 58820/60000 (98%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9577/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0010, Accuracy: 58814/60000 (98%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9577/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0009, Accuracy: 58850/60000 (98%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9572/10000 (96%)\n",
      "\n",
      "Size: 25\n",
      "\n",
      "Test set: Avg. loss: 0.0023, Accuracy: 918/10000 (9%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0060, Accuracy: 53325/60000 (89%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9266/10000 (93%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0034, Accuracy: 56199/60000 (94%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9429/10000 (94%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0027, Accuracy: 56990/60000 (95%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0001, Accuracy: 9548/10000 (95%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0023, Accuracy: 57416/60000 (96%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0001, Accuracy: 9582/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0020, Accuracy: 57701/60000 (96%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0001, Accuracy: 9615/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0018, Accuracy: 57948/60000 (97%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0001, Accuracy: 9613/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0017, Accuracy: 58093/60000 (97%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0001, Accuracy: 9614/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0016, Accuracy: 58119/60000 (97%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0001, Accuracy: 9638/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0015, Accuracy: 58287/60000 (97%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0001, Accuracy: 9659/10000 (97%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0014, Accuracy: 58345/60000 (97%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0001, Accuracy: 9604/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0013, Accuracy: 58434/60000 (97%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0001, Accuracy: 9651/10000 (97%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0013, Accuracy: 58529/60000 (98%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0001, Accuracy: 9638/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0012, Accuracy: 58585/60000 (98%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0001, Accuracy: 9662/10000 (97%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0012, Accuracy: 58634/60000 (98%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0001, Accuracy: 9623/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0011, Accuracy: 58634/60000 (98%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0001, Accuracy: 9618/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0011, Accuracy: 58694/60000 (98%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0001, Accuracy: 9633/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0010, Accuracy: 58749/60000 (98%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0001, Accuracy: 9650/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0010, Accuracy: 58761/60000 (98%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0001, Accuracy: 9615/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0010, Accuracy: 58819/60000 (98%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0001, Accuracy: 9641/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0009, Accuracy: 58866/60000 (98%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0001, Accuracy: 9617/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0009, Accuracy: 58883/60000 (98%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0001, Accuracy: 9641/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0009, Accuracy: 58920/60000 (98%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0001, Accuracy: 9622/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0009, Accuracy: 58904/60000 (98%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0001, Accuracy: 9648/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0008, Accuracy: 58961/60000 (98%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0001, Accuracy: 9622/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0008, Accuracy: 58973/60000 (98%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0001, Accuracy: 9611/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0008, Accuracy: 59016/60000 (98%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0001, Accuracy: 9648/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0008, Accuracy: 58998/60000 (98%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0001, Accuracy: 9612/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0008, Accuracy: 59055/60000 (98%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0001, Accuracy: 9621/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0007, Accuracy: 59083/60000 (98%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0001, Accuracy: 9630/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0007, Accuracy: 59082/60000 (98%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9612/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0007, Accuracy: 59145/60000 (99%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0001, Accuracy: 9627/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0007, Accuracy: 59144/60000 (99%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9611/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0007, Accuracy: 59186/60000 (99%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0001, Accuracy: 9631/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0007, Accuracy: 59148/60000 (99%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0001, Accuracy: 9630/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0007, Accuracy: 59172/60000 (99%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9611/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0006, Accuracy: 59210/60000 (99%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9589/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0006, Accuracy: 59213/60000 (99%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9603/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0006, Accuracy: 59263/60000 (99%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9605/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0006, Accuracy: 59263/60000 (99%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9622/10000 (96%)\n",
      "\n",
      "\n",
      "Train set: Avg. loss: 0.0006, Accuracy: 59316/60000 (99%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002, Accuracy: 9598/10000 (96%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for size in range(5, 30, 5):\n",
    "    print(f\"Size: {size}\")\n",
    "    train_test(size=size, epochs=40, step=10, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cosypose",
   "language": "python",
   "name": "cosypose"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
